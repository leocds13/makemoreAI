{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "import torch\n",
    "# import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57750,\n",
       " ['adao',\n",
       "  'adelina',\n",
       "  'adelson',\n",
       "  'ademar',\n",
       "  'ademir',\n",
       "  'adenilson',\n",
       "  'adilson',\n",
       "  'adriana',\n",
       "  'adriano',\n",
       "  'adriele'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"nomes_br.csv\"\n",
    "words = []\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    words = f.read().lower().splitlines()\n",
    "\n",
    "file = \"names.txt\"\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for w in f.read().lower().splitlines():\n",
    "        words.append(w) \n",
    "words = list(dict.fromkeys(words))\n",
    "len(words), words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#build the vocabulary os chars and mapping to/from integers\n",
    "chars = ['.']+sorted(list(set(''.join(words))))\n",
    "ctoi = {c:i for i,c in enumerate(chars)}\n",
    "itoc = {i:c for c,i in ctoi.items()}\n",
    "vocab_size = len(itoc)\n",
    "print(itoc)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([348607, 3]) torch.Size([348607])\n",
      "torch.Size([43537, 3]) torch.Size([43537])\n",
      "torch.Size([43738, 3]) torch.Size([43738])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = ctoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "# training split, dev/validation split, test split\n",
    "# 80%, 10% , 10%\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10\n",
    "n_hidden = 200\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_emb),                generator=g)\n",
    "\n",
    "W1 = torch.randn((n_emb * block_size, n_hidden),    generator=g) * ((5/3) / ((n_emb*block_size) ** 0.5))\n",
    "b1 = torch.randn(n_hidden,                          generator=g) * 0.1\n",
    "\n",
    "W2 = torch.randn((n_hidden, vocab_size),            generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                        generator=g) * 0.1\n",
    "\n",
    "bngain = torch.ones((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.zeros((1, n_hidden)) * 0.1\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden)) \n",
    "\n",
    "parameters = [C, W1, W2, b2, b1, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6527, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(max_steps):\n",
    "\n",
    "# minibatch construct\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "# foward pass\n",
    "emb = C[Xb] # [32, 3, 2]\n",
    "emb_cat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "# layer1\n",
    "hprebn = emb_cat @ W1 + b1\n",
    "#batchNorm layer\n",
    "# bnstdi = hpreact.std(0, keepdim=True)\n",
    "# hpreact = bngain * (hpreact - (bnmeani if calcBn else bnmean_running)) / (bnstdi if calcBn else bnstd_running)  + bnbias\n",
    "bnmeani = 1/batch_size * hprebn.sum(0, keepdim=True) \n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff ** 2\n",
    "bnvar = 1/(batch_size-1)*(bndiff2).sum(0, keepdim=True)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "# if calcBn:\n",
    "#     with torch.no_grad():\n",
    "#         bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani \n",
    "#         bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi \n",
    "\n",
    "# h = torch.tanh(hpreact) # (32, 100)\n",
    "# logits = h @ W2 + b2\n",
    "\n",
    "# cross entropy loss (same as F.corss_entropy)\n",
    "# loss = F.cross_entropy(logits, Yb)\n",
    "logits_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logits_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(batch_size), Yb].mean()\n",
    "\n",
    "\n",
    "# backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "            norm_logits, logits_maxes, logits, h, hpreact, bnraw,\n",
    "            bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, b1,\n",
    "            emb_cat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n",
    "#update\n",
    "# lr = 0.1 #if i < max_steps/2 else (0.01 if i < max_steps * 0.75 else 0.005) # lrs[i]\n",
    "# for p in parameters:\n",
    "#     p.data += -lr * p.grad\n",
    "\n",
    "# track stats\n",
    "# if i % 10000 == 0:\n",
    "#     print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "# lossi.append(loss.log10().item())\n",
    "\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 10])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits.shape, logits.max(1, keepdim=True).values.shape\n",
    "# F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) # HERE ZEROS AND ONES\n",
    "# emb = C[Xb]\n",
    "print(emb.shape, C.shape, Xb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb_cat         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# EX 1\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(batch_size), Yb] = -1.0 / batch_size\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "dcounts_sum = (-counts_sum ** -2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "dlogits_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp('logits_maxes', dlogits_maxes, logits_maxes)\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogits_maxes\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "dh = dlogits @ W2.T\n",
    "dw2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('h', dh, h)\n",
    "cmp('w2', dw2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5) ** -1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "dbndiff2 = (1.0/(batch_size-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbndiff += (2 * bndiff) * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "\n",
    "dhprebn = dbndiff.clone()\n",
    "dhprebn += 1.0/batch_size * torch.ones_like(hprebn) * dbnmeani\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "demb_cat = dhprebn @ W1.T\n",
    "dw1 = emb_cat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('emb_cat', demb_cat, emb_cat)\n",
    "cmp('w1', dw1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "demb = demb_cat.view(emb.shape)\n",
    "cmp('emb', demb, emb)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# EX: 2\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(batch_size), Yb] -= 1\n",
    "dlogits /= batch_size\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23eee3e13d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# Ex: 3\n",
    "dhprebn = bngain*bnvar_inv/batch_size * (batch_size * dhpreact - dhpreact.sum(0) - batch_size/(batch_size-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.6527\n",
      "  10000/ 200000: 2.2319\n",
      "  20000/ 200000: 2.1993\n",
      "  30000/ 200000: 2.3055\n",
      "  40000/ 200000: 2.3515\n",
      "  50000/ 200000: 2.2431\n",
      "  60000/ 200000: 1.8821\n",
      "  70000/ 200000: 1.8398\n",
      "  80000/ 200000: 2.5758\n",
      "  90000/ 200000: 1.9537\n",
      " 100000/ 200000: 1.9298\n",
      " 110000/ 200000: 2.0243\n",
      " 120000/ 200000: 1.9337\n",
      " 130000/ 200000: 2.2860\n",
      " 140000/ 200000: 2.2015\n",
      " 150000/ 200000: 2.0227\n",
      " 160000/ 200000: 1.8778\n",
      " 170000/ 200000: 1.9759\n",
      " 180000/ 200000: 2.6277\n",
      " 190000/ 200000: 2.2362\n",
      "2.2176673412323\n"
     ]
    }
   ],
   "source": [
    "# EX: 4\n",
    "\n",
    "#init\n",
    "n_emb = 10\n",
    "n_hidden = 200\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_emb),                generator=g)\n",
    "\n",
    "W1 = torch.randn((n_emb * block_size, n_hidden),    generator=g) * ((5/3) / ((n_emb*block_size) ** 0.5))\n",
    "b1 = torch.randn(n_hidden,                          generator=g) * 0.1\n",
    "\n",
    "W2 = torch.randn((n_hidden, vocab_size),            generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                        generator=g) * 0.1\n",
    "\n",
    "bngain = torch.ones((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.zeros((1, n_hidden)) * 0.1\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden)) \n",
    "\n",
    "parameters = [C, W1, W2, b2, b1, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "        # foward pass\n",
    "        emb = C[Xb] # [32, 3, 2]\n",
    "        emb_cat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "        # layer1\n",
    "        hprebn = emb_cat @ W1 + b1\n",
    "        # batchNorm layer\n",
    "        bnmeani = 1/batch_size * hprebn.sum(0, keepdim=True) \n",
    "        bndiff = hprebn - bnmeani\n",
    "        bndiff2 = bndiff ** 2\n",
    "        bnvar = 1/(batch_size-1)*(bndiff2).sum(0, keepdim=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = bndiff * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact)\n",
    "        # Linear layer 2\n",
    "        logits = h @ W2 + b2\n",
    "\n",
    "        logits_maxes = logits.max(1, keepdim=True).values\n",
    "        norm_logits = logits - logits_maxes\n",
    "        counts = norm_logits.exp()\n",
    "        counts_sum = counts.sum(1, keepdim=True)\n",
    "        counts_sum_inv = counts_sum**-1\n",
    "        probs = counts * counts_sum_inv\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(batch_size), Yb].mean()\n",
    "\n",
    "        # backward pass\n",
    "        # for p in parameters:\n",
    "        #     p.grad = None\n",
    "        # loss.backward()\n",
    "            \n",
    "        # My Backprop\n",
    "        dC, dw1, db1, dw2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n",
    "        # dlogprobs = torch.zeros_like(logprobs)\n",
    "        # dlogprobs[range(batch_size), Yb] = -1.0 / batch_size\n",
    "        # dprobs = (1.0 / probs) * dlogprobs\n",
    "        # dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "        # dcounts_sum = (-counts_sum ** -2) * dcounts_sum_inv\n",
    "        # dcounts = counts_sum_inv * dprobs\n",
    "        # dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "        # dnorm_logits = counts * dcounts\n",
    "        # dlogits_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "        # dlogits = dnorm_logits.clone()\n",
    "        # dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogits_maxes\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(batch_size), Yb] -= 1\n",
    "        dlogits /= batch_size\n",
    "\n",
    "        dh = dlogits @ W2.T\n",
    "        dw2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "        # dbnraw = bngain * dhpreact\n",
    "        # dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "        # dbnvar = (-0.5 * (bnvar + 1e-5) ** -1.5) * dbnvar_inv\n",
    "        # dbndiff2 = (1.0/(batch_size-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "        # dbndiff = bnvar_inv * dbnraw\n",
    "        # dbndiff += (2 * bndiff) * dbndiff2\n",
    "        # dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "        # dhprebn = dbndiff.clone()\n",
    "        # dhprebn += 1.0/batch_size * torch.ones_like(hprebn) * dbnmeani\n",
    "        dhprebn = bngain * bnvar_inv / batch_size * (batch_size * dhpreact - dhpreact.sum(0) - batch_size / (batch_size-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
    "\n",
    "        demb_cat = dhprebn @ W1.T\n",
    "        dw1 = emb_cat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        demb = demb_cat.view(emb.shape)\n",
    "        dC = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k, j]\n",
    "                dC[ix] += demb[k, j]\n",
    "        grads = [dC, dw1, dw2, db2, db1, dbngain, dbnbias]\n",
    "\n",
    "        #update\n",
    "        lr = 0.1 if i < max_steps/2 else (0.01 if i < max_steps * 0.75 else 0.005) # lrs[i]\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad\n",
    "            p.data += -lr * grad\n",
    "        \n",
    "        # track stats\n",
    "        if i % 10000 == 0:\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "        # if i % 1000 == 0:\n",
    "        #     break\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-08\n",
      "(30, 200)       | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-08\n",
      "(200, 27)       | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(27,)           | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(200,)          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# for p, g in zip(parameters, grads):\n",
    "#     cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    bnmean_running = hpreact.mean(0, keepdim=True)\n",
    "    bnvar_running = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.085801124572754\n",
      "val 2.1062376499176025\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte)\n",
    "    }[split]\n",
    "    emb = C[x] # [32, 3, 2]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # hpreact = bngain * (hpreact - hpreact.mean(0, keepdim=True)) / hpreact.std(0, keepdim=True) + bnbias\n",
    "    # hpreact = bngain * (hpreact - bnmean_running) / bnvar_running + bnbias\n",
    "    hpreact = bngain * (hpreact - bnmean_running) * (bnvar_running + 1e-5) ** -0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (32, 100)\n",
    "    logits = h @ W2 + b2\n",
    "    # logits = feedfoward(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eria.\n",
      "gryanna.\n",
      "elvid.\n",
      "ryah.\n",
      "renerson.\n",
      "dra.\n",
      "grazeem.\n",
      "selithelizoparedeiseana.\n",
      "arleitzio.\n",
      "lura.\n",
      "noshubergias.\n",
      "jessin.\n",
      "joselle.\n",
      "josenifeubertedir.\n",
      "yah.\n",
      "freds.\n",
      "kayshaston.\n",
      "azhilianayansufinaldo.\n",
      "juren.\n",
      "cristiviaostino.\n"
     ]
    }
   ],
   "source": [
    "# sample from model\n",
    "g1 = torch.Generator().manual_seed(2147483647+10)\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        hpreact = embcat @ W1 #+ b1\n",
    "        # hpreact = bngain * (hpreact - hpreact.mean(0, keepdim=True)) / hpreact.std(0, keepdim=True) + bnbias\n",
    "        # hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "        hpreact = bngain * (hpreact - bnmean_running) * (bnvar_running + 1e-5) ** -0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (32, 100)\n",
    "        logits = h @ W2 + b2\n",
    "        # logits = feedfoward(torch.tensor([context]))\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g1).item()\n",
    "        context = context[1:]+[ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itoc[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Makemore-7ynZQ-KU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
